{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMuqEylSax3r"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mFph0jVawzw"
      },
      "outputs": [],
      "source": [
        "import os, json, math, random, argparse, time, glob, shutil\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import math, random, json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import cv2\n",
        "from typing import Dict, Any, Tuple\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib.colors import Normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVHd2ywUaxZj"
      },
      "source": [
        "# Dataset Generation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM04uL6Rth_S"
      },
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 2) DATA GENERATION & DATASET  (functions only – not executed yet)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def render_frame(theta: float, L_px: int = 20, res: int = 51) -> np.ndarray:\n",
        "    \"\"\"Gaussian bob on a small canvas.\"\"\"\n",
        "    cx, cy = res // 2, res // 6\n",
        "    bx = cx + L_px * math.sin(theta)\n",
        "    by = cy + L_px * math.cos(theta)\n",
        "    y, x = np.mgrid[0:res, 0:res].astype(np.float32)\n",
        "    return np.exp(-((x - bx) ** 2 + (y - by) ** 2) / (L_px * 2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------- integrator -------------------------------\n",
        "def pendulum_theta(t: np.ndarray, theta0: float, omega0: float, g: float, L_m: float) -> np.ndarray:\n",
        "    dt = t[1] - t[0]\n",
        "    theta, omega = np.zeros_like(t), np.zeros_like(t)\n",
        "    theta[0], omega[0] = theta0, omega0\n",
        "    for i in range(1, len(t)):\n",
        "        k1 = -g / L_m * math.sin(theta[i - 1]); q1 = omega[i - 1]\n",
        "        k2 = -g / L_m * math.sin(theta[i - 1] + 0.5 * dt * q1)\n",
        "        q2 = omega[i - 1] + 0.5 * dt * k1\n",
        "        k3 = -g / L_m * math.sin(theta[i - 1] + 0.5 * dt * q2)\n",
        "        q3 = omega[i - 1] + 0.5 * dt * k2\n",
        "        k4 = -g / L_m * math.sin(theta[i - 1] + dt * q3)\n",
        "        q4 = omega[i - 1] + dt * k3\n",
        "        theta[i] = theta[i - 1] + dt/6 * (q1 + 2*q2 + 2*q3 + q4)\n",
        "        omega[i] = omega[i - 1] + dt/6 * (k1 + 2*k2 + 2*k3 + k4)\n",
        "    return theta"
      ],
      "metadata": {
        "id": "QSs1nbDNjXsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 2) DATA GENERATION & DATASET\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def generate_dataset(\n",
        "    num_clips: int = 10**7,\n",
        "    fps: float = 50,  # dt=0.02[s]\n",
        "    seq_min_frames: int = 16,  # Min sequence length\n",
        "    seq_max_frames: int = 32,  # Max sequence length\n",
        "    res: int = 51,\n",
        "    out_root: str = \"./data\",\n",
        "    g: float = 9.81,\n",
        "    L_m: float = 1.0,\n",
        "    max_size_gb: int = 10):\n",
        "\n",
        "    dt = 1.0 / fps  # dt = 0.02[s]\n",
        "\n",
        "    out_root = Path(out_root)\n",
        "    tensor_dir = out_root / \"tensors\"; tensor_dir.mkdir(parents=True, exist_ok=True)\n",
        "    bytes_limit = max_size_gb * (1024 ** 3)\n",
        "    bytes_written = 0\n",
        "    bytes_per_frame = res * res * 4\n",
        "    clip_idx = 0\n",
        "\n",
        "    shards_by_length = {}\n",
        "    shard_bytes_by_length = {}\n",
        "\n",
        "    pbar = tqdm(total=num_clips, desc=\"clips\")\n",
        "    while clip_idx < num_clips and bytes_written < bytes_limit:\n",
        "        seq_length = random.randint(seq_min_frames, seq_max_frames)\n",
        "\n",
        "        # Random initial conditions\n",
        "        theta0 = random.uniform(-math.pi/2, math.pi/2)\n",
        "        omega0 = random.uniform(-1.0, 1.0)\n",
        "\n",
        "        # Energy check to ensure no full rotations\n",
        "        E = g*L_m*(1-math.cos(theta0)) + 0.5*(L_m*omega0)**2\n",
        "        if E >= 2*g*L_m:\n",
        "            continue\n",
        "\n",
        "        t_array = np.arange(seq_length) * dt\n",
        "        theta_arr = pendulum_theta(t_array, theta0, omega0, g, L_m)\n",
        "\n",
        "        frames = np.stack([render_frame(th, res=res) for th in theta_arr])\n",
        "\n",
        "        if seq_length not in shards_by_length:\n",
        "            shards_by_length[seq_length] = []\n",
        "            shard_bytes_by_length[seq_length] = 0\n",
        "\n",
        "        shards_by_length[seq_length].append(torch.from_numpy(frames).unsqueeze(1))\n",
        "\n",
        "        this_bytes = seq_length * bytes_per_frame\n",
        "        shard_bytes_by_length[seq_length] += this_bytes\n",
        "        bytes_written += this_bytes\n",
        "        clip_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "        if shard_bytes_by_length[seq_length] > 1e9 or bytes_written >= bytes_limit:\n",
        "            length_shard = shards_by_length[seq_length]\n",
        "            if length_shard:\n",
        "                torch.save(\n",
        "                    torch.stack(length_shard),\n",
        "                    tensor_dir / f\"shard_len{seq_length}_{clip_idx:07d}.pt\"\n",
        "                )\n",
        "                shards_by_length[seq_length] = []\n",
        "                shard_bytes_by_length[seq_length] = 0\n",
        "\n",
        "    for seq_length, shard in shards_by_length.items():\n",
        "        if shard:\n",
        "            torch.save(\n",
        "                torch.stack(shard),\n",
        "                tensor_dir / f\"shard_len{seq_length}_final.pt\"\n",
        "            )\n",
        "\n",
        "    pbar.close()\n",
        "    print(f\"Saved {clip_idx} clips, {bytes_written/1e9:.2f} GB\")\n",
        "    print(f\"Variable sequence lengths: {seq_min_frames}-{seq_max_frames} frames ({seq_min_frames/fps:.2f}-{seq_max_frames/fps:.2f} seconds at fps={fps})\")"
      ],
      "metadata": {
        "id": "IW-9SFw1ja3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rq4cHuethvk"
      },
      "source": [
        "# Data Class & Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 3) PendulumTensorDataset\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "class PendulumTensorDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tensor_root: str):\n",
        "        self.paths = sorted(Path(tensor_root).glob(\"shard_len*.pt\"))\n",
        "        self.offsets = []\n",
        "        total = 0\n",
        "\n",
        "        print(f\"Found {len(self.paths)} tensor files in {tensor_root}\")\n",
        "\n",
        "        for p in self.paths:\n",
        "            try:\n",
        "                tensor = torch.load(p, mmap=True)\n",
        "                n = tensor.shape[0]\n",
        "                self.offsets.append((total, p, n))\n",
        "                total += n\n",
        "                print(f\"Loaded {p.name} with {n} sequences\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {p}: {e}\")\n",
        "\n",
        "        self.N = total\n",
        "        print(f\"Total dataset size: {self.N} sequences\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.N\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        for start, path, n in self.offsets:\n",
        "            if idx < start + n:\n",
        "                try:\n",
        "                    tensor = torch.load(path, mmap=True)[idx - start]\n",
        "                    return tensor\n",
        "                except Exception as e:\n",
        "                    print(f\"Error accessing index {idx} in {path}: {e}\")\n",
        "                    raise\n",
        "        raise IndexError(f\"Index {idx} out of bounds for dataset of size {self.N}\")"
      ],
      "metadata": {
        "id": "CvG7jt_RmWta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# collate function for batching variable length sequences\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def variable_length_collate(batch):\n",
        "    # Extract sequences and determine their lengths\n",
        "    sequences = batch  # Assuming batch is a list of sequences\n",
        "    seq_lengths = [seq.shape[0] for seq in sequences]  # Get sequence length from first dimension\n",
        "\n",
        "    # Find the max sequence length in this batch\n",
        "    max_len = max(seq_lengths)\n",
        "\n",
        "    # Get other dimensions from the first sequence\n",
        "    _, C, H, W = sequences[0].shape\n",
        "\n",
        "    # Prepare padded batch tensor\n",
        "    batch_size = len(sequences)\n",
        "    padded_batch = torch.zeros(batch_size, max_len, C, H, W, device=sequences[0].device)\n",
        "\n",
        "    # Fill in the actual sequences\n",
        "    for i, (seq, length) in enumerate(zip(sequences, seq_lengths)):\n",
        "        padded_batch[i, :length] = seq\n",
        "\n",
        "    # Return padded batch and sequence lengths for masking in loss computation\n",
        "    return (padded_batch, torch.tensor(seq_lengths, device=sequences[0].device))"
      ],
      "metadata": {
        "id": "UiQfDlq61VJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2u8zRNotqcl"
      },
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 4) Updated DATA LOADERS (with variable sequence handling)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "def build_loaders(tensor_root: str, batch: int = 32, num_workers: int = 4):\n",
        "    full = PendulumTensorDataset(tensor_root)\n",
        "\n",
        "    if len(full) == 0:\n",
        "        raise ValueError(f\"No data found in {tensor_root}\")\n",
        "\n",
        "    test_size = min(20, len(full) // 10)\n",
        "    val_size = int(0.1 * (len(full) - test_size))\n",
        "    train_size = len(full) - val_size - test_size\n",
        "\n",
        "    print(f\"Splitting dataset: Train={train_size}, Val={val_size}, Test={test_size}\")\n",
        "\n",
        "    # Create torch Generator with fixed seed for reproducibility\n",
        "    generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "    train_set, val_set, test_set = random_split(\n",
        "        full, [train_size, val_size, test_size],\n",
        "        generator=generator\n",
        "    )\n",
        "\n",
        "    # Use the variable_length_collate function for handling variable sequence lengths\n",
        "    loader = lambda ds, shuffle: DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=num_workers if num_workers > 0 else 0,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=num_workers > 0,\n",
        "        collate_fn=variable_length_collate  # Use custom collate function\n",
        "    )\n",
        "\n",
        "    return loader(train_set, True), loader(val_set, False), loader(test_set, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfRZXP9btqrD"
      },
      "source": [
        "# SINDy Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAHEUOgUtuuP"
      },
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 4)  SINDy FRAMEWORK  (single‑coordinate library Θ(z) & helpers)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "class PolyTrigLibrary(nn.Module):\n",
        "    \"\"\"Return [z, sin z, z², z³]\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(); self.out_dim = 4\n",
        "    def forward(self, z):\n",
        "        return torch.cat([z, torch.sin(z), z**2, z**3], dim=-1)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Bayesian helpers (SSGL prior, SGLD, EMVS)\n",
        "# -----------------------------\n",
        "@torch.no_grad()\n",
        "def emvs_update(Xi, rho, kappa, v0=1., v1=5., delta=0.1):\n",
        "    lap = torch.distributions.Laplace(0, v0)\n",
        "    gau = torch.distributions.Normal(0, v1)\n",
        "    p1 = gau.log_prob(Xi).exp() * delta\n",
        "    p0 = lap.log_prob(Xi).exp() * (1 - delta)\n",
        "    rho_new = p1 / (p1 + p0 + 1e-12)\n",
        "    k0 = (1 - rho_new) / v0\n",
        "    k1 = rho_new / v1\n",
        "    return rho_new, (k0, k1)\n",
        "\n",
        "def sgld_step(param, grad, lr):\n",
        "    param.data.add_(-0.5 * lr * grad + torch.randn_like(param) * math.sqrt(lr))\n",
        "\n",
        "def ss_gl_log_prob(Xi, rho, kappa):\n",
        "    lap_part = (1 - rho) * torch.abs(Xi) / kappa[0]\n",
        "    # Use torch.log instead of math.log for tensor operations\n",
        "    log_term = torch.log(torch.tensor(2 * math.pi).to(Xi.device) * kappa[1])\n",
        "    gauss_part = 0.5 * rho * (Xi**2) / kappa[1] + 0.5 * rho * log_term\n",
        "    return (lap_part + gauss_part).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4cbgTwhuZZ6"
      },
      "outputs": [],
      "source": [
        "def print_equation(Xi:torch.Tensor):\n",
        "    terms = [\"θ\",\"sin θ\",\"θ²\",\"θ³\"]\n",
        "    coefs = Xi.view(-1).tolist()\n",
        "    eq = \"θ̈ = \" + \" + \".join([f\"{c:.3g}*{t}\" for c,t in zip(coefs,terms) if abs(c)>0])\n",
        "    print(eq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q3YG0Lptw-q"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, input_channels, hidden_channels, kernel_size=3):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        padding = kernel_size // 2\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            input_channels + hidden_channels,\n",
        "            4 * hidden_channels,\n",
        "            kernel_size,\n",
        "            padding=padding\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tensor, hidden_state):\n",
        "        h_prev, c_prev = hidden_state\n",
        "\n",
        "        combined = torch.cat([input_tensor, h_prev], dim=1)\n",
        "\n",
        "        conv_output = self.conv(combined)\n",
        "\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(conv_output, self.hidden_channels, dim=1)\n",
        "\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_prev + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next"
      ],
      "metadata": {
        "id": "HBGYIMuwAyQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f4ONi4GtxV2"
      },
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 5) MODEL  (Encoder + Bayesian‑SINDy + Decoder)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "class ConvLSTMEncoder(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial feature extraction\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 5, 2, 2),  # 51×51 → 26×26\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 5, 2, 2),  # 26×26 → 13×13\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # ConvLSTM layer\n",
        "        self.convlstm = ConvLSTMCell(32, 64)\n",
        "\n",
        "        # Output projection\n",
        "        feature_size = 64 * 13 * 13\n",
        "        self.fc_mu  = nn.Linear(feature_size, cfg['latent_dim'])\n",
        "        self.fc_log = nn.Linear(feature_size, cfg['latent_dim'])\n",
        "\n",
        "    def forward(self, x_seq):\n",
        "        # x_seq: (B, T, C, H, W)\n",
        "        batch_size, seq_len = x_seq.size(0), x_seq.size(1)\n",
        "\n",
        "        # Hidden state init\n",
        "        h = torch.zeros(batch_size, 64, 13, 13, device=x_seq.device)\n",
        "        c = torch.zeros(batch_size, 64, 13, 13, device=x_seq.device)\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            frame = x_seq[:, t]          # (B, 1, 51, 51)\n",
        "            x1 = self.conv1(frame)       # (B, 16, 26, 26)\n",
        "            x2 = self.conv2(x1)          # (B, 32, 13, 13)\n",
        "            h, c = self.convlstm(x2, (h, c))\n",
        "\n",
        "        h_flat = h.reshape(batch_size, -1)\n",
        "        mu   = self.fc_mu(h_flat)\n",
        "        logv = self.fc_log(h_flat)\n",
        "        z    = mu + torch.randn_like(mu) * torch.exp(0.5 * logv)  # reparam\n",
        "\n",
        "        return z, mu, logv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 3) Bayesian SINDy‑RNN cell\n",
        "# -----------------------------\n",
        "class BayesianSINDyCell(nn.Module):\n",
        "    \"\"\"\n",
        "    z_{t+1} = z_t + h · Φ(z_t) · Ξ           (Euler micro-steps)\n",
        "\n",
        "    Ξ has an independent Gaussian posterior\n",
        "        q(Ξ_ij) = N(μ_ij, σ_ij²)\n",
        "    and we keep the closed-form KL term so the training loop can add it.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    library   : nn.Module   – maps z → Φ(z)  (out_dim)\n",
        "    dt        : float       – macro time-step\n",
        "    k_micro   : int         – # Euler sub-steps per dt\n",
        "    prior_std : float       – σ₀ of the N(0, σ₀²) prior over Ξ\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 library: nn.Module,\n",
        "                 dt: float,\n",
        "                 k_micro: int = 1,\n",
        "                 prior_std: float = 1e-1):\n",
        "        super().__init__()\n",
        "        assert library.in_dim == 1, \"please fucking work I've been on this shit for 5 hours\"\n",
        "        self.lib = library\n",
        "        self.dt  = dt\n",
        "        self.k   = k_micro\n",
        "\n",
        "        # variational parameters of Ξ  (μ, log σ)\n",
        "        self.mu         = nn.Parameter(1e-4 * torch.randn(library.out_dim, 1))\n",
        "        self.log_sigma  = nn.Parameter(torch.full((library.out_dim, 1), -3.0))\n",
        "\n",
        "        self.register_buffer(\"prior_var\", torch.tensor(prior_std ** 2))\n",
        "        self.kl = torch.tensor(0.)\n",
        "\n",
        "    # -----------------------------------------------------------------\n",
        "    def _sample_Xi(self) -> torch.Tensor:\n",
        "        eps = torch.randn_like(self.mu)\n",
        "        return self.mu + torch.exp(self.log_sigma) * eps\n",
        "\n",
        "    # -----------------------------------------------------------------\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : (B, 1)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        z_next : (B, 1)\n",
        "        \"\"\"\n",
        "        Xi = self._sample_Xi()          # (out_dim, 1)\n",
        "        h  = self.dt / self.k\n",
        "        for _ in range(self.k):\n",
        "            Phi = self.lib(z)           # (B, out_dim)\n",
        "            z   = z + h * (Phi @ Xi)    # (B, 1)\n",
        "\n",
        "        # analytic KL[q(Ξ)||p(Ξ)]\n",
        "        var_q = torch.exp(2 * self.log_sigma)\n",
        "        self.kl = 0.5 * torch.sum(\n",
        "            (self.mu ** 2 + var_q) / self.prior_var - 1 +\n",
        "            torch.log(self.prior_var) - 2 * self.log_sigma\n",
        "        )\n",
        "        return z"
      ],
      "metadata": {
        "id": "H-jFm-XoFFZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL6QhEPRt4uq"
      },
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# DeconvDecoder\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "class DeconvDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1, 64 * 7 * 7),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1),  # 7×7 → 14×14\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 16, 4, 2, 1),  # 14×14 → 28×28\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16)\n",
        "        )\n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 8, 4, 2, 1),   # 28×28 → 56×56\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(8)\n",
        "        )\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Conv2d(8, 1, 3, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        batch_size = z.size(0)\n",
        "        x = self.fc(z).view(batch_size, 64, 7, 7)\n",
        "        x = self.deconv1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.deconv3(x)\n",
        "        x = self.final(x)\n",
        "\n",
        "        if x.shape[-1] != 51:\n",
        "            x = F.interpolate(x, size=(51, 51), mode='bilinear', align_corners=False)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c27WvOt6t2Q8"
      },
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 5)  MODEL  – FullModel  (enc + latent + decoder)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "class BayesianSINDyRNN(nn.Module):\n",
        "    \"\"\"Encoder → Bayesian-SINDy latent RNN → Decoder\"\"\"\n",
        "\n",
        "    def __init__(self, cfg: Dict[str, Any]):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.enc = ConvLSTMEncoder(cfg)\n",
        "\n",
        "        lib = PolyTrigLibrary(cfg['latent_dim'])\n",
        "\n",
        "        self.cell = BayesianSINDyCell(\n",
        "            library     = lib,\n",
        "            dt          = cfg['dt'],\n",
        "            k_micro     = cfg['k_micro'],\n",
        "            latent_dim  = cfg['latent_dim'],\n",
        "            prior_std   = cfg.get('prior_std', 1e-1)\n",
        "        )\n",
        "\n",
        "        self.dec = DeconvDecoder()\n",
        "\n",
        "        # KL weight from cfg\n",
        "        self.beta_kl = cfg.get('beta_kl', 1.0)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    def forward(self, x_seq: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
        "        z0, mu_e, logvar_e = self.enc(x_seq)   # (B, latent_dim)\n",
        "        z_pred = self.cell(z0)                 # (B, latent_dim)\n",
        "        x_rec  = self.dec(z_pred)              # (B, 1, H, W)\n",
        "\n",
        "        return {\n",
        "            'z0':       z0,\n",
        "            'z_pred':   z_pred,\n",
        "            'x_rec':    x_rec,\n",
        "            'kl_lat':   self.cell.kl,\n",
        "            'mu_e':     mu_e,\n",
        "            'logvar_e': logvar_e\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AbN4_iqt2l_"
      },
      "source": [
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "114OsgN5t8NE"
      },
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# compute_loss  (second-order)\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "def compute_loss(batch_data, model, rho, kappa, cfg):\n",
        "    batch, seq_lengths = batch_data\n",
        "    B = batch.shape[0]\n",
        "    losses = {'rec': 0, 'pred': 0, 'acc': 0, 'lat': 0, 'kld': 0}\n",
        "    valid_sequences = 0\n",
        "\n",
        "    for i in range(B):\n",
        "        seq_len = seq_lengths[i].item()\n",
        "        if seq_len < 3:\n",
        "            continue\n",
        "\n",
        "        sequence = batch[i, :seq_len].unsqueeze(0)\n",
        "        out = model(sequence)\n",
        "\n",
        "        z_t, mu, lv      = out['z'], out['mu'], out['logvar']\n",
        "        z_tm1, _, _      = model.enc(sequence[:, :-1].contiguous())\n",
        "        z_pred, x_rec    = out['z_pred'], out['x_rec']\n",
        "\n",
        "        L_rec  = F.mse_loss(sequence[:, -1], x_rec)\n",
        "        z_gt_tp1 = z_t + (z_t - z_tm1)\n",
        "        L_pred = F.mse_loss(z_pred, z_gt_tp1.detach())\n",
        "\n",
        "        dt2 = cfg['dt'] ** 2\n",
        "        z_ddot_fd  = (z_pred - 2 * z_t + z_tm1) / dt2\n",
        "        z_ddot_est = model.cell.lib(z_t) @ model.cell.Xi\n",
        "        L_acc  = F.mse_loss(z_ddot_est, z_ddot_fd.detach())\n",
        "        L_lat  = F.mse_loss(z_pred, z_t.detach())\n",
        "        KLD    = -0.5 * torch.mean(1 + lv - mu ** 2 - lv.exp())\n",
        "\n",
        "        losses['rec']  += L_rec.item()\n",
        "        losses['pred'] += L_pred.item()\n",
        "        losses['acc']  += L_acc.item()\n",
        "        losses['lat']  += L_lat.item()\n",
        "        losses['kld']  += KLD.item()\n",
        "        valid_sequences += 1\n",
        "\n",
        "    if valid_sequences == 0:\n",
        "        return torch.tensor(0., requires_grad=True, device=batch.device), {k: 0. for k in losses}\n",
        "\n",
        "    for k in losses:\n",
        "        losses[k] /= valid_sequences\n",
        "\n",
        "    L_prior = ss_gl_log_prob(model.cell.Xi, rho, kappa)\n",
        "    loss_tensor = (\n",
        "        L_rec +\n",
        "        L_pred +\n",
        "        0.1 * L_acc +\n",
        "        cfg['lambda_lat'] * L_lat +\n",
        "        1e-4 * KLD +\n",
        "        cfg['lambda_prior'] * L_prior\n",
        "    )\n",
        "    metrics = {**losses, 'prior': L_prior.item()}\n",
        "    return loss_tensor, metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Ul7GDFt-39"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_coef():\n",
        "    magnitude = 10 ** random.uniform(-1, 1)  # Random magnitude between 10^-1 and 10\n",
        "    sign = random.choice([-1, 1])            # Random sign\n",
        "    return sign * magnitude"
      ],
      "metadata": {
        "id": "hFX-vKHSd2Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkNLC2x3t_lS"
      },
      "outputs": [],
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# training.py  –  Adam (encoder/decoder)  +  Cyclic-SGLD (μ, log σ)\n",
        "#                 for the Bayesian-SINDy latent model\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "#\n",
        "#   * Encoder & Decoder are trained with Adam.\n",
        "#   * The variational SINDy parameters   μ , log σ\n",
        "#     are updated with a cyclical Stochastic-Gradient-Langevin–Dynamics\n",
        "#     step whose learning–rate oscillates between lr_xi_lo ↔ lr_xi_hi\n",
        "#     every `cycle_steps` iterations.\n",
        "#   * We still keep a *hard-pruning* mask on μ\n",
        "#     so coefficients that shrink below a tolerance stay permanently zero.\n",
        "#\n",
        "#   Dependencies:  compute_loss, ss_gl_log_prob, print_equation,\n",
        "#                  random_coef\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "# ---------------------------------------------------------------------\n",
        "#  train()\n",
        "# ---------------------------------------------------------------------\n",
        "def train(model,\n",
        "          loaders: Tuple[torch.utils.data.DataLoader,\n",
        "                         torch.utils.data.DataLoader,\n",
        "                         torch.utils.data.DataLoader],\n",
        "          cfg: Dict[str, Any],\n",
        "          epochs: int = 1500,\n",
        "          save_root: str = \"/content/drive/MyDrive/ProjectFinalBSRVAE10\"):\n",
        "    \"\"\"\n",
        "    End-to-end training routine for ConvLSTM-Encoder → Bayesian-SINDy-RNN → Decoder.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model      : nn.Module\n",
        "        Complete network (enc · latent · dec).\n",
        "    loaders    : (train_loader, val_loader, test_loader)\n",
        "        Each loader returns  (videos, seq_lengths).\n",
        "    cfg        : dict\n",
        "        Must contain: device, dt, lambda_lat, lambda_prior, lr_encdec,\n",
        "        lr_xi_hi, lr_xi_lo, cycle_steps  (see CFG example in notebook).\n",
        "    \"\"\"\n",
        "    train_loader, val_loader, _ = loaders\n",
        "    device = cfg[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 1) Hard-pruning mask over μ\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    model.pruned_mask = torch.zeros_like(model.cell.mu,\n",
        "                                         dtype=torch.bool, device=device)\n",
        "\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 2) Initialise μ with small random SINDy coefficients\n",
        "    #      (log σ already initialised by the cell)\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    with torch.no_grad():\n",
        "        model.cell.mu[:] = torch.tensor([\n",
        "            [random_coef()],        # θ\n",
        "            [random_coef()],        # sin θ\n",
        "            [random_coef()],        # θ²\n",
        "            [random_coef()]         # θ³\n",
        "        ], device=device, dtype=torch.float32)\n",
        "    print(\"μ (initial coefficients):\",\n",
        "          model.cell.mu.data.squeeze().tolist())\n",
        "\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 3) Optimisers\n",
        "    #    • Adam  – encoder & decoder\n",
        "    #    • dummy SGD  – provides lr to CyclicLR for  μ, log σ\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    encdec_params = list(model.enc.parameters()) + list(model.dec.parameters())\n",
        "    xi_params     = [model.cell.mu, model.cell.log_sigma]\n",
        "\n",
        "    opt_encdec = torch.optim.Adam(encdec_params, lr=cfg[\"lr_encdec\"])\n",
        "    opt_xi     = torch.optim.SGD(xi_params, lr=cfg[\"lr_xi_hi\"])  # dummy\n",
        "\n",
        "    xi_scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
        "        opt_xi,\n",
        "        base_lr=cfg[\"lr_xi_lo\"],\n",
        "        max_lr=cfg[\"lr_xi_hi\"],\n",
        "        step_size_up=cfg[\"cycle_steps\"],\n",
        "        mode=\"triangular2\",\n",
        "        cycle_momentum=False\n",
        "    )\n",
        "\n",
        "    # SS-GL prior hyper-parameters (same shapes as μ)\n",
        "    rho   = torch.zeros_like(model.cell.mu, device=device)\n",
        "    kappa = (torch.ones_like(model.cell.mu, device=device),\n",
        "             torch.ones_like(model.cell.mu, device=device) * 5.0)\n",
        "\n",
        "    # bookkeeping\n",
        "    history  = {\"epoch\": [], \"train\": [], \"val\": []}\n",
        "    ckpt_dir = Path(save_root) / \"checkpoints\"\n",
        "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    # 4) Main epoch loop\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "    try:\n",
        "        for ep in range(1, epochs + 1):\n",
        "\n",
        "            # ========== TRAINING ==========\n",
        "            model.train()\n",
        "            train_metrics = {k: 0. for k in\n",
        "                             [\"rec\", \"pred\", \"acc\", \"lat\", \"kld\",\n",
        "                              \"prior\", \"total\"]}\n",
        "            n_batches = 0\n",
        "\n",
        "            for batch_data in train_loader:\n",
        "                # push tensors to GPU\n",
        "                batch_data = tuple(t.to(device) if isinstance(t, torch.Tensor)\n",
        "                                   else t for t in batch_data)\n",
        "\n",
        "                # forward / loss\n",
        "                loss, mets = compute_loss(batch_data, model, rho, kappa, cfg)\n",
        "                mets[\"prior\"] = (ss_gl_log_prob(model.cell.mu, rho, kappa)\n",
        "                                 .item() * cfg[\"lambda_prior\"])\n",
        "                mets[\"total\"] = loss.item()\n",
        "\n",
        "                # ---- zero grads ----\n",
        "                opt_encdec.zero_grad()\n",
        "                for p in xi_params:\n",
        "                    p.grad = None\n",
        "\n",
        "                # ---- backward ----\n",
        "                loss.backward()\n",
        "\n",
        "                # ---- Adam step (enc/dec) ----\n",
        "                opt_encdec.step()\n",
        "\n",
        "                # ---- Cyclic-SGLD step (μ, log σ) ----\n",
        "                lr_xi = xi_scheduler.get_last_lr()[0] # current LR\n",
        "                for p in xi_params:\n",
        "                    if p.grad is None:\n",
        "                        continue\n",
        "                    noise = torch.randn_like(p)\n",
        "                    p.data.add_( -lr_xi * p.grad\n",
        "                                 + math.sqrt(2.0 * lr_xi) * noise )\n",
        "                    p.grad.zero_()\n",
        "                xi_scheduler.step()\n",
        "\n",
        "                # ---- hard-prune small μ entries ----\n",
        "                with torch.no_grad():\n",
        "                    mask = model.cell.mu.abs() <= 1e-4\n",
        "                    model.pruned_mask |= mask\n",
        "                    model.cell.mu[model.pruned_mask] = 0.0\n",
        "                    # (no need to mask gradients niggas are zeroed)\n",
        "\n",
        "                # accumulate stats\n",
        "                for k, v in mets.items():\n",
        "                    train_metrics[k] += v\n",
        "                n_batches += 1\n",
        "\n",
        "            if n_batches:\n",
        "                train_metrics = {k: v / n_batches for k, v in train_metrics.items()}\n",
        "\n",
        "            # ========== VALIDATION ==========\n",
        "            model.eval()\n",
        "            val_metrics = {k: 0. for k in train_metrics}\n",
        "            n_val = 0\n",
        "            with torch.no_grad():\n",
        "                for batch_data in val_loader:\n",
        "                    batch_data = tuple(t.to(device) if isinstance(t, torch.Tensor)\n",
        "                                       else t for t in batch_data)\n",
        "                    loss, mets = compute_loss(batch_data, model, rho, kappa, cfg)\n",
        "                    mets[\"prior\"] = (ss_gl_log_prob(model.cell.mu, rho, kappa)\n",
        "                                     .item() * cfg[\"lambda_prior\"])\n",
        "                    mets[\"total\"] = loss.item()\n",
        "                    for k, v in mets.items():\n",
        "                        val_metrics[k] += v\n",
        "                    n_val += 1\n",
        "            if n_val:\n",
        "                val_metrics = {k: v / n_val for k, v in val_metrics.items()}\n",
        "\n",
        "            # ========== BOOKKEEPING ==========\n",
        "            history[\"epoch\"].append(ep)\n",
        "            history[\"train\"].append(train_metrics)\n",
        "            history[\"val\"].append(val_metrics)\n",
        "\n",
        "            print(f\"Epoch {ep:03d} | \"\n",
        "                  f\"REC {train_metrics['rec']:.3e}/{val_metrics['rec']:.3e} | \"\n",
        "                  f\"PRED {train_metrics['pred']:.3e}/{val_metrics['pred']:.3e} | \"\n",
        "                  f\"ACC {train_metrics['acc']:.3e}/{val_metrics['acc']:.3e}\")\n",
        "\n",
        "            if ep % 10 == 0:\n",
        "                print(f\"\\n--- mean SINDy equation at epoch {ep} ---\")\n",
        "                print_equation(model.cell.mu)          # human-readable form\n",
        "\n",
        "            torch.save({\n",
        "                \"epoch\": ep,\n",
        "                \"model_state\": model.state_dict(),\n",
        "                \"mu\": model.cell.mu.detach().cpu(),\n",
        "                \"log_sigma\": model.cell.log_sigma.detach().cpu(),\n",
        "                \"pruned_mask\": model.pruned_mask.detach().cpu(),\n",
        "                \"history\": history,\n",
        "            }, ckpt_dir / f\"epoch_{ep:04d}.pt\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Training interrupted by user.\")\n",
        "\n",
        "    finally:\n",
        "        # final checkpoint & history\n",
        "        torch.save({\n",
        "            \"epoch\": ep if \"ep\" in locals() else 0,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"mu\": model.cell.mu.detach().cpu(),\n",
        "            \"log_sigma\": model.cell.log_sigma.detach().cpu(),\n",
        "            \"pruned_mask\": model.pruned_mask.detach().cpu(),\n",
        "            \"history\": history,\n",
        "        }, ckpt_dir / \"final.pt\")\n",
        "\n",
        "        with open(Path(save_root) / \"training_history.json\", \"w\") as f:\n",
        "            json.dump(history, f, indent=2)\n",
        "\n",
        "        # explicit dataloader clean-up (multiprocessing)\n",
        "        del train_loader, val_loader, _\n",
        "        return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebnQcOsfunYK"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# 1) Hyper‑parameters\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "CFG = {\n",
        "        \"latent_dim\":    1,                         # dimensionality of θ\n",
        "        \"dt\":            0.02,                      # time step (s)\n",
        "        \"k_micro\":       16,                        # Euler micro‑steps per frame\n",
        "        \"lambda_lat\":    1e-2,                      # weight on latent‑alignment loss\n",
        "        \"lambda_prior\":  1e-4,                      # weight on SSGL prior (–log p(Ξ))\n",
        "        \"lr_encdec\":     1e-3,                      # Adam LR for encoder & decoder\n",
        "        \"lr_xi_hi\":      1e-3,                      # maximum LR for cyclical SGLD on Ξ\n",
        "        \"lr_xi_lo\":      1e-5,                      # minimum LR for cyclical SGLD on Ξ\n",
        "        \"cycle_steps\":   500,                       # length of one cosine cycle for SGLD\n",
        "        \"rho_thresh\":    0.05,                      # hard‑prune threshold on inclusion prob ρ\n",
        "        \"prior_std\":     1e-1,                      # σ₀ in the N(0,σ₀²) prior over Ξ\n",
        "        \"beta_kl\":       1.0,                       # weight on KL_lat term  (β-VAE style)\n",
        "        \"device\":        \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        \"use_encoder_kl\": True,\n",
        "        \"beta_enc\":      1.0,\n",
        "}"
      ],
      "metadata": {
        "id": "OHBRpFxQobwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Dataset"
      ],
      "metadata": {
        "id": "vqNMju7SocZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_ROOT = \"/content/drive/MyDrive/ProjectFinalBSRVAE10\"\n",
        "TENSOR_DIR = Path(OUT_ROOT) / \"tensors\""
      ],
      "metadata": {
        "id": "GmuriOs-8qAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrDLs2g8uoJG"
      },
      "outputs": [],
      "source": [
        "generate_dataset(\n",
        "    num_clips = 5_000,\n",
        "    fps = 50,              # 50 Hz (dt = 0.02s)\n",
        "    seq_min_frames = 16,   # Minimum sequence length (16 frames = 0.32s)\n",
        "    seq_max_frames = 32,   # Maximum sequence length (32 frames = 0.64s)\n",
        "    res = 51,\n",
        "    out_root = OUT_ROOT,\n",
        "    g = 9.81,\n",
        "    L_m = 1.0,\n",
        "    max_size_gb = 10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljzR1h-Vuryb"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_pendulum_sequence(tensor_dir, sequence_idx=0, output_path=\"pendulum_animation.mp4\"):\n",
        "    # Verify tensor directory exists\n",
        "    tensor_dir = Path(tensor_dir)\n",
        "    if not tensor_dir.exists():\n",
        "        raise FileNotFoundError(f\"Tensor directory not found: {tensor_dir}\")\n",
        "\n",
        "    # List all tensor files\n",
        "    tensor_files = sorted(list(tensor_dir.glob(\"shard_len*.pt\")))\n",
        "    if not tensor_files:\n",
        "        raise FileNotFoundError(f\"No tensor files found in {tensor_dir}\")\n",
        "\n",
        "    print(f\"Found {len(tensor_files)} tensor files.\")\n",
        "\n",
        "    # Load a sequence directly from file\n",
        "    file_idx = 0\n",
        "    try:\n",
        "        tensor_data = torch.load(tensor_files[file_idx])\n",
        "        if sequence_idx >= tensor_data.shape[0]:\n",
        "            sequence_idx = 0\n",
        "            print(f\"Requested index too large. Using index 0 instead.\")\n",
        "        sequence = tensor_data[sequence_idx]\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading tensor: {e}\")\n",
        "        # Try loading a different file if available\n",
        "        if len(tensor_files) > 1:\n",
        "            print(\"Trying next file...\")\n",
        "            tensor_data = torch.load(tensor_files[1])\n",
        "            sequence = tensor_data[0]\n",
        "        else:\n",
        "            raise RuntimeError(\"Failed to load any valid tensor data.\")\n",
        "\n",
        "    print(f\"Sequence shape: {sequence.shape}\")\n",
        "\n",
        "    # Create figure and axis\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    ax = plt.subplot(111)\n",
        "\n",
        "    # Initial frame\n",
        "    frame_data = sequence[0, 0].numpy()  # First frame, first channel\n",
        "    norm = Normalize(vmin=0, vmax=frame_data.max())\n",
        "    img = ax.imshow(frame_data, cmap='viridis', norm=norm, animated=True)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Animation function\n",
        "    def update(frame):\n",
        "        if frame < sequence.shape[0]:\n",
        "            frame_data = sequence[frame, 0].numpy()\n",
        "            img.set_array(frame_data)\n",
        "        return [img]\n",
        "\n",
        "    # Create animation\n",
        "    ani = animation.FuncAnimation(\n",
        "        fig, update, frames=sequence.shape[0],\n",
        "        interval=40,  # 40ms between frames (~25 fps)\n",
        "        blit=True\n",
        "    )\n",
        "\n",
        "    # Save as MP4\n",
        "    try:\n",
        "        writer = animation.FFMpegWriter(fps=25, metadata=dict(artist='Me'), bitrate=1800)\n",
        "        ani.save(output_path, writer=writer)\n",
        "        print(f\"Animation saved to {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving animation: {e}\")\n",
        "        print(\"Trying to save as GIF instead...\")\n",
        "        try:\n",
        "            ani.save(output_path.replace('.mp4', '.gif'), writer='pillow')\n",
        "            print(f\"Animation saved as GIF\")\n",
        "        except Exception as e2:\n",
        "            print(f\"Error saving GIF: {e2}\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    # If in a notebook environment, also display the animation\n",
        "    try:\n",
        "        from IPython.display import HTML, display\n",
        "        if os.path.exists(output_path):\n",
        "            display(HTML(f'<video width=\"500\" height=\"500\" controls><source src=\"{output_path}\" type=\"video/mp4\"></video>'))\n",
        "    except ImportError:\n",
        "        pass"
      ],
      "metadata": {
        "id": "4Udo1eMs3kGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_ROOT = \"/content/drive/MyDrive/ProjectFinalBSRVAE10\"\n",
        "TENSOR_DIR = Path(OUT_ROOT) / \"tensors\"\n",
        "\n",
        "visualize_pendulum_sequence(\n",
        "    tensor_dir=TENSOR_DIR,\n",
        "    sequence_idx=0,\n",
        "    output_path=\"pendulum_example.mp4\"\n",
        ")"
      ],
      "metadata": {
        "id": "pxy_JVVr3lki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WrZNFh8uuwZ"
      },
      "source": [
        "# Data Loaders & Start of Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_ROOT = Path(\"/content/drive/MyDrive/ProjectFinalBSRVAE10\")\n",
        "TENSOR_DIR = OUT_ROOT / \"tensors\"\n",
        "\n",
        "train_loader, val_loader, test_loader = build_loaders(\n",
        "    tensor_root=TENSOR_DIR,\n",
        "    batch=32,\n",
        "    num_workers=9\n",
        ")"
      ],
      "metadata": {
        "id": "SDLpG2iROdQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BayesianSINDyRNN(CFG)\n",
        "history = train(\n",
        "    model,\n",
        "    (train_loader, val_loader, test_loader),\n",
        "    CFG,\n",
        "    epochs = 1500,\n",
        "    save_root = OUT_ROOT\n",
        ")"
      ],
      "metadata": {
        "id": "KZOk7DLK16Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoints & Evaluation Functions"
      ],
      "metadata": {
        "id": "gbN1S88akkOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run '/content/drive/MyDrive/ProjectFinalBSRVAE10/model_functions.py'"
      ],
      "metadata": {
        "id": "6iwcv1QZn3YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_path, model, device):\n",
        "    \"\"\"Load model checkpoint and return the epoch number and training history.\"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "    if 'Xi' in checkpoint:\n",
        "        model.cell.Xi.data = checkpoint['Xi'].to(device)\n",
        "\n",
        "    if 'pruned_mask' in checkpoint:\n",
        "        model.pruned_mask = checkpoint['pruned_mask'].to(device)\n",
        "    else:\n",
        "        model.pruned_mask = torch.zeros_like(model.cell.Xi, dtype=torch.bool, device=device)\n",
        "\n",
        "    history = checkpoint.get('history', {'epoch': [], 'train': [], 'val': []})\n",
        "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
        "\n",
        "    return start_epoch, history"
      ],
      "metadata": {
        "id": "end6hESIEIYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, cfg, checkpoint_path=None, output_dir=\"./evaluation_results\"):\n",
        "    device = cfg['device']\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if checkpoint_path is not None:\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state'])\n",
        "        print(f\"Loaded model from {checkpoint_path}\")\n",
        "\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    mse_reconstruction = []\n",
        "    mse_prediction = []\n",
        "    latent_trajectories = []\n",
        "    ground_truth_frames = []\n",
        "    reconstructed_frames = []\n",
        "    predicted_frames = []\n",
        "\n",
        "    # Extract the SINDy coefficients\n",
        "    sindy_coefficients = model.cell.Xi.detach().cpu().numpy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch_data in enumerate(tqdm(test_loader, desc=\"Evaluating\")):\n",
        "            batch, seq_lengths = tuple(t.to(device) if isinstance(t, torch.Tensor) else t for t in batch_data)\n",
        "\n",
        "            for i in range(batch.shape[0]):\n",
        "                seq_len = seq_lengths[i].item()\n",
        "                if seq_len < 3:\n",
        "                    continue\n",
        "\n",
        "                sequence = batch[i, :seq_len].unsqueeze(0)  # Add batch dimension back\n",
        "\n",
        "                # Split into input and target for prediction evaluation\n",
        "                input_seq = sequence[:, :-1]\n",
        "                target_frame = sequence[:, -1]\n",
        "\n",
        "                # Forward pass\n",
        "                out = model(input_seq)\n",
        "                z_t = out['z']  # Current latent state\n",
        "\n",
        "                # Get previous latent state\n",
        "                if input_seq.shape[1] > 1:\n",
        "                    _, z_tm1, _ = model.enc(input_seq[:, :-1])\n",
        "                else:\n",
        "                    # If only one frame, use a zero vector as previous state\n",
        "                    z_tm1 = torch.zeros_like(z_t)\n",
        "\n",
        "                # Predict next latent state\n",
        "                z_pred = model.cell(z_t)\n",
        "\n",
        "                # Decode the predicted latent state\n",
        "                x_pred = model.dec(z_pred)\n",
        "\n",
        "                # Reconstruction from current latent state\n",
        "                x_rec = model.dec(z_t)\n",
        "\n",
        "                # Calculate metrics\n",
        "                rec_mse = nn.MSELoss()(x_rec, target_frame).item()\n",
        "                pred_mse = nn.MSELoss()(x_pred, target_frame).item()\n",
        "\n",
        "                mse_reconstruction.append(rec_mse)\n",
        "                mse_prediction.append(pred_mse)\n",
        "\n",
        "                # Store the first few sequences for visualization\n",
        "                if batch_idx < 5:\n",
        "                    # Store latent trajectory\n",
        "                    latent_trajectories.append({\n",
        "                        'current': z_t.squeeze().cpu().numpy(),\n",
        "                        'predicted': z_pred.squeeze().cpu().numpy()\n",
        "                    })\n",
        "\n",
        "                    # Store frames for visualization\n",
        "                    ground_truth_frames.append(target_frame.squeeze().cpu().numpy())\n",
        "                    reconstructed_frames.append(x_rec.squeeze().cpu().numpy())\n",
        "                    predicted_frames.append(x_pred.squeeze().cpu().numpy())\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_rec_mse = np.mean(mse_reconstruction)\n",
        "    avg_pred_mse = np.mean(mse_prediction)\n",
        "\n",
        "    print(f\"Average Reconstruction MSE: {avg_rec_mse:.6f}\")\n",
        "    print(f\"Average Prediction MSE: {avg_pred_mse:.6f}\")\n",
        "\n",
        "    # Create visualizations\n",
        "\n",
        "    # 1. Visualization of SINDy coefficients\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    terms = [\"θ\", \"sin θ\", \"θ²\", \"θ³\"]\n",
        "\n",
        "    # Plot coefficients as a bar chart\n",
        "    plt.bar(terms, sindy_coefficients.squeeze(), color='blue', alpha=0.7)\n",
        "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "    plt.title(\"Discovered SINDy Coefficients\", fontsize=14)\n",
        "    plt.ylabel(\"Coefficient Value\", fontsize=12)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add true equation for comparison\n",
        "    plt.figtext(0.5, 0.01, \"True equation: θ̈ = -9.81*sin(θ)\", ha=\"center\", fontsize=12,\n",
        "                bbox={\"facecolor\":\"orange\", \"alpha\":0.2, \"pad\":5})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path / \"sindy_coefficients.png\", dpi=300)\n",
        "\n",
        "    # 2. Compare frame reconstruction and prediction\n",
        "    if ground_truth_frames:\n",
        "        n_samples = min(5, len(ground_truth_frames))\n",
        "        fig, axes = plt.subplots(n_samples, 3, figsize=(15, 3*n_samples))\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            # Ground truth\n",
        "            im0 = axes[i, 0].imshow(ground_truth_frames[i], cmap='viridis')\n",
        "            axes[i, 0].set_title(\"Ground Truth\" if i == 0 else \"\")\n",
        "            axes[i, 0].axis('off')\n",
        "\n",
        "            # Reconstruction\n",
        "            im1 = axes[i, 1].imshow(reconstructed_frames[i], cmap='viridis')\n",
        "            axes[i, 1].set_title(\"Reconstruction\" if i == 0 else \"\")\n",
        "            axes[i, 1].axis('off')\n",
        "\n",
        "            # Prediction\n",
        "            im2 = axes[i, 2].imshow(predicted_frames[i], cmap='viridis')\n",
        "            axes[i, 2].set_title(\"Prediction\" if i == 0 else \"\")\n",
        "            axes[i, 2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_path / \"frame_comparison.png\", dpi=300)\n",
        "\n",
        "    # 3. Latent space visualization\n",
        "    if latent_trajectories:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        for i, traj in enumerate(latent_trajectories[:5]):\n",
        "            plt.scatter(i, traj['current'], color='blue', label='Current' if i == 0 else \"\")\n",
        "            plt.scatter(i+0.5, traj['predicted'], color='red', label='Predicted' if i == 0 else \"\")\n",
        "            plt.plot([i, i+0.5], [traj['current'], traj['predicted']], 'k--', alpha=0.5)\n",
        "\n",
        "        plt.xlabel(\"Sequence Index\")\n",
        "        plt.ylabel(\"Latent Value\")\n",
        "        plt.title(\"Latent Space Trajectories\")\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_path / \"latent_trajectories.png\", dpi=300)\n",
        "\n",
        "    # 4. Error distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(mse_reconstruction, kde=True, color='blue')\n",
        "    plt.title(\"Reconstruction MSE\")\n",
        "    plt.xlabel(\"MSE\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.histplot(mse_prediction, kde=True, color='red')\n",
        "    plt.title(\"Prediction MSE\")\n",
        "    plt.xlabel(\"MSE\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path / \"error_distribution.png\", dpi=300)\n",
        "\n",
        "    # 5. Generate pendulum equation comparison\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # Define the actual pendulum equation: θ̈ = -g/L * sin(θ)\n",
        "    g = 9.81  # gravity\n",
        "    L = 1.0   # length (as in your simulation)\n",
        "\n",
        "    # Create theta values for plotting\n",
        "    theta = np.linspace(-np.pi, np.pi, 1000)\n",
        "\n",
        "    # True acceleration\n",
        "    true_accel = -g/L * np.sin(theta)\n",
        "\n",
        "    # Model predicted acceleration\n",
        "    # Extract coefficients for readability\n",
        "    coef_theta = sindy_coefficients[0, 0]\n",
        "    coef_sin = sindy_coefficients[1, 0]\n",
        "    coef_theta2 = sindy_coefficients[2, 0]\n",
        "    coef_theta3 = sindy_coefficients[3, 0]\n",
        "\n",
        "    predicted_accel = (coef_theta * theta +\n",
        "                       coef_sin * np.sin(theta) +\n",
        "                       coef_theta2 * theta**2 +\n",
        "                       coef_theta3 * theta**3)\n",
        "\n",
        "    # Plot\n",
        "    ax.plot(theta, true_accel, 'b-', linewidth=2, label='True: $\\\\ddot{\\\\theta} = -9.81 \\\\sin(\\\\theta)$')\n",
        "    ax.plot(theta, predicted_accel, 'r--', linewidth=2,\n",
        "            label=f'Discovered: $\\\\ddot{{\\\\theta}} = {coef_theta:.3f}\\\\theta + {coef_sin:.3f}\\\\sin(\\\\theta) + {coef_theta2:.3f}\\\\theta^2 + {coef_theta3:.3f}\\\\theta^3$')\n",
        "\n",
        "    ax.set_xlabel(r'$\\theta$ (radians)', fontsize=14)\n",
        "    ax.set_ylabel(r'$\\ddot{\\theta}$ (rad/s²)', fontsize=14)\n",
        "    ax.set_title('Comparison of True vs Discovered Pendulum Dynamics', fontsize=16)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path / \"equation_comparison.png\", dpi=300)\n",
        "\n",
        "    # Return metrics for further analysis if needed\n",
        "    return {\n",
        "        'avg_reconstruction_mse': avg_rec_mse,\n",
        "        'avg_prediction_mse': avg_pred_mse,\n",
        "        'sindy_coefficients': sindy_coefficients\n",
        "    }\n",
        "\n",
        "# Function to generate phase space visualization\n",
        "def visualize_phase_space(model, output_dir=\"./evaluation_results\"):\n",
        "    \"\"\"\n",
        "    Visualize the pendulum phase space using the discovered equation\n",
        "    \"\"\"\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Extract SINDy coefficients\n",
        "    with torch.no_grad():\n",
        "        Xi = model.cell.Xi.detach().cpu().numpy().squeeze()\n",
        "\n",
        "    # Define the state space grid\n",
        "    theta = np.linspace(-np.pi, np.pi, 20)\n",
        "    omega = np.linspace(-5, 5, 20)\n",
        "\n",
        "    THETA, OMEGA = np.meshgrid(theta, omega)\n",
        "\n",
        "    # Compute vector field using discovered coefficients\n",
        "    # dθ/dt = ω\n",
        "    # dω/dt = Xi[0]*θ + Xi[1]*sin(θ) + Xi[2]*θ² + Xi[3]*θ³\n",
        "\n",
        "    dTHETA = OMEGA\n",
        "\n",
        "    # Apply the SINDy equation to get dω/dt\n",
        "    dOMEGA = (Xi[0] * THETA +\n",
        "              Xi[1] * np.sin(THETA) +\n",
        "              Xi[2] * THETA**2 +\n",
        "              Xi[3] * THETA**3)\n",
        "\n",
        "    # Calculate vector magnitudes for color mapping\n",
        "    magnitude = np.sqrt(dTHETA**2 + dOMEGA**2)\n",
        "\n",
        "    # Normalize the vectors for better visualization\n",
        "    norm = np.sqrt(dTHETA**2 + dOMEGA**2)\n",
        "    norm[norm == 0] = 1  # Prevent division by zero\n",
        "    dTHETA_norm = dTHETA / norm\n",
        "    dOMEGA_norm = dOMEGA / norm\n",
        "\n",
        "    # Create the phase portrait\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.quiver(THETA, OMEGA, dTHETA_norm, dOMEGA_norm, magnitude, cmap='viridis',\n",
        "               pivot='mid', alpha=0.8)\n",
        "\n",
        "    # Add streamlines for clearer flow visualization\n",
        "    plt.streamplot(THETA, OMEGA, dTHETA, dOMEGA, color='white', linewidth=0.5, density=1.5, arrowsize=0.5)\n",
        "\n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.set_label('Vector magnitude', rotation=270, labelpad=15)\n",
        "\n",
        "    # Add grid\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Set labels and title\n",
        "    plt.xlabel(r'$\\theta$ (radians)', fontsize=12)\n",
        "    plt.ylabel(r'$\\omega$ (rad/s)', fontsize=12)\n",
        "    plt.title('Phase Space Portrait using Discovered Dynamics', fontsize=14)\n",
        "\n",
        "    # Add the discovered equation as text\n",
        "    equation_text = f\"Discovered equation: $\\\\ddot{{\\\\theta}} = {Xi[0]:.3f}\\\\theta + {Xi[1]:.3f}\\\\sin(\\\\theta) + {Xi[2]:.3f}\\\\theta^2 + {Xi[3]:.3f}\\\\theta^3$\"\n",
        "    plt.figtext(0.5, 0.01, equation_text, ha=\"center\", fontsize=12,\n",
        "                bbox={\"facecolor\":\"white\", \"alpha\":0.8, \"pad\":5})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path / \"phase_space.png\", dpi=300)\n",
        "\n",
        "    # Create energy level contours\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Simplified pendulum energy function: E = 0.5*ω² + g/L*(1-cos(θ))\n",
        "    g = 9.81\n",
        "    L = 1.0\n",
        "    E = 0.5 * OMEGA**2 + g/L * (1 - np.cos(THETA))\n",
        "\n",
        "    # Plot contour lines of constant energy\n",
        "    plt.contourf(THETA, OMEGA, E, levels=20, cmap='coolwarm', alpha=0.7)\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.set_label('Energy', rotation=270, labelpad=15)\n",
        "\n",
        "    # Overlay the vector field\n",
        "    plt.quiver(THETA, OMEGA, dTHETA_norm, dOMEGA_norm, alpha=0.5, color='k')\n",
        "\n",
        "    # Set labels and title\n",
        "    plt.xlabel(r'$\\theta$ (radians)', fontsize=12)\n",
        "    plt.ylabel(r'$\\omega$ (rad/s)', fontsize=12)\n",
        "    plt.title('Energy Levels and Vector Field', fontsize=14)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path / \"energy_levels.png\", dpi=300)\n",
        "\n",
        "    # Return the coefficients for reference\n",
        "    return Xi\n",
        "\n",
        "# Simulation function to generate pendulum trajectories using the learned model\n",
        "def simulate_pendulum_trajectories(model, initial_conditions, n_steps=50, dt=0.02, output_dir=\"./evaluation_results\"):\n",
        "    \"\"\"\n",
        "    Simulate pendulum trajectories using the discovered dynamics\n",
        "\n",
        "    Args:\n",
        "        model: Trained SINDy-RNN model\n",
        "        initial_conditions: List of (theta0, omega0) tuples\n",
        "        n_steps: Number of simulation steps\n",
        "        dt: Time step size\n",
        "        output_dir: Directory to save results\n",
        "    \"\"\"\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Extract SINDy coefficients\n",
        "    with torch.no_grad():\n",
        "        Xi = model.cell.Xi.detach().cpu().numpy().squeeze()\n",
        "\n",
        "    # True pendulum parameters\n",
        "    g = 9.81\n",
        "    L = 1.0\n",
        "\n",
        "    # Prepare figure\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # For each initial condition\n",
        "    for i, (theta0, omega0) in enumerate(initial_conditions):\n",
        "        # Initialize arrays for true and predicted trajectories\n",
        "        true_theta = np.zeros(n_steps)\n",
        "        true_omega = np.zeros(n_steps)\n",
        "        pred_theta = np.zeros(n_steps)\n",
        "        pred_omega = np.zeros(n_steps)\n",
        "\n",
        "        # Set initial conditions\n",
        "        true_theta[0] = theta0\n",
        "        true_omega[0] = omega0\n",
        "        pred_theta[0] = theta0\n",
        "        pred_omega[0] = omega0\n",
        "\n",
        "        # Simulate using RK4\n",
        "        for t in range(1, n_steps):\n",
        "            # True dynamics using RK4\n",
        "            k1_theta = true_omega[t-1]\n",
        "            k1_omega = -g/L * np.sin(true_theta[t-1])\n",
        "\n",
        "            k2_theta = true_omega[t-1] + 0.5 * dt * k1_omega\n",
        "            k2_omega = -g/L * np.sin(true_theta[t-1] + 0.5 * dt * k1_theta)\n",
        "\n",
        "            k3_theta = true_omega[t-1] + 0.5 * dt * k2_omega\n",
        "            k3_omega = -g/L * np.sin(true_theta[t-1] + 0.5 * dt * k2_theta)\n",
        "\n",
        "            k4_theta = true_omega[t-1] + dt * k3_omega\n",
        "            k4_omega = -g/L * np.sin(true_theta[t-1] + dt * k3_theta)\n",
        "\n",
        "            true_theta[t] = true_theta[t-1] + dt/6 * (k1_theta + 2*k2_theta + 2*k3_theta + k4_theta)\n",
        "            true_omega[t] = true_omega[t-1] + dt/6 * (k1_omega + 2*k2_omega + 2*k3_omega + k4_omega)\n",
        "\n",
        "            # Discovered dynamics using RK4\n",
        "            k1_theta = pred_omega[t-1]\n",
        "            k1_omega = Xi[0]*pred_theta[t-1] + Xi[1]*np.sin(pred_theta[t-1]) + Xi[2]*pred_theta[t-1]**2 + Xi[3]*pred_theta[t-1]**3\n",
        "\n",
        "            k2_theta = pred_omega[t-1] + 0.5 * dt * k1_omega\n",
        "            k2_omega = Xi[0]*(pred_theta[t-1] + 0.5 * dt * k1_theta) + \\\n",
        "                      Xi[1]*np.sin(pred_theta[t-1] + 0.5 * dt * k1_theta) + \\\n",
        "                      Xi[2]*(pred_theta[t-1] + 0.5 * dt * k1_theta)**2 + \\\n",
        "                      Xi[3]*(pred_theta[t-1] + 0.5 * dt * k1_theta)**3\n",
        "\n",
        "            k3_theta = pred_omega[t-1] + 0.5 * dt * k2_omega\n",
        "            k3_omega = Xi[0]*(pred_theta[t-1] + 0.5 * dt * k2_theta) + \\\n",
        "                      Xi[1]*np.sin(pred_theta[t-1] + 0.5 * dt * k2_theta) + \\\n",
        "                      Xi[2]*(pred_theta[t-1] + 0.5 * dt * k2_theta)**2 + \\\n",
        "                      Xi[3]*(pred_theta[t-1] + 0.5 * dt * k2_theta)**3\n",
        "\n",
        "            k4_theta = pred_omega[t-1] + dt * k3_omega\n",
        "            k4_omega = Xi[0]*(pred_theta[t-1] + dt * k3_theta) + \\\n",
        "                      Xi[1]*np.sin(pred_theta[t-1] + dt * k3_theta) + \\\n",
        "                      Xi[2]*(pred_theta[t-1] + dt * k3_theta)**2 + \\\n",
        "                      Xi[3]*(pred_theta[t-1] + dt * k3_theta)**3\n",
        "\n",
        "            pred_theta[t] = pred_theta[t-1] + dt/6 * (k1_theta + 2*k2_theta + 2*k3_theta + k4_theta)\n",
        "            pred_omega[t] = pred_omega[t-1] + dt/6 * (k1_omega + 2*k2_omega + 2*k3_omega + k4_omega)\n",
        "\n",
        "        # Plot state vs time\n",
        "        plt.subplot(len(initial_conditions), 2, 2*i+1)\n",
        "        plt.plot(np.arange(n_steps)*dt, true_theta, 'b-', label='True θ')\n",
        "        plt.plot(np.arange(n_steps)*dt, pred_theta, 'r--', label='Discovered θ')\n",
        "        if i == 0:\n",
        "            plt.title('Angle (θ) vs Time')\n",
        "        plt.xlabel('Time (s)' if i == len(initial_conditions)-1 else '')\n",
        "        plt.ylabel(f'θ (rad), IC={theta0:.1f}, {omega0:.1f}')\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(len(initial_conditions), 2, 2*i+2)\n",
        "        plt.plot(np.arange(n_steps)*dt, true_omega, 'b-', label='True ω')\n",
        "        plt.plot(np.arange(n_steps)*dt, pred_omega, 'r--', label='Discovered ω')\n",
        "        if i == 0:\n",
        "            plt.title('Angular Velocity (ω) vs Time')\n",
        "        plt.xlabel('Time (s)' if i == len(initial_conditions)-1 else '')\n",
        "        plt.ylabel('ω (rad/s)')\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path / \"trajectory_comparison.png\", dpi=300)\n",
        "\n",
        "    # Plot Phase space trajs\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for i, (theta0, omega0) in enumerate(initial_conditions):\n",
        "        # Phase space trajs\n",
        "        true_theta = np.zeros(n_steps)\n",
        "        true_omega = np.zeros(n_steps)\n",
        "        pred_theta = np.zeros(n_steps)\n",
        "        pred_omega = np.zeros(n_steps)\n",
        "\n",
        "        # ICs\n",
        "        true_theta[0] = theta0\n",
        "        true_omega[0] = omega0\n",
        "        pred_theta[0] = theta0\n",
        "        pred_omega[0] = omega0\n",
        "\n",
        "        # Simulate via RK4\n",
        "        for t in range(1, n_steps):\n",
        "            # True dynamics\n",
        "            k1_theta = true_omega[t-1]\n",
        "            k1_omega = -g/L * np.sin(true_theta[t-1])\n",
        "\n",
        "            k2_theta = true_omega[t-1] + 0.5 * dt * k1_omega\n",
        "            k2_omega = -g/L * np.sin(true_theta[t-1] + 0.5 * dt * k1_theta)\n",
        "\n",
        "            k3_theta = true_omega[t-1] + 0.5 * dt * k2_omega\n",
        "            k3_omega = -g/L * np.sin(true_theta[t-1] + 0.5 * dt * k2_theta)\n",
        "\n",
        "            k4_theta = true_omega[t-1] + dt * k3_omega\n",
        "            k4_omega = -g/L * np.sin(true_theta[t-1] + dt * k3_theta)\n",
        "\n",
        "            true_theta[t] = true_theta[t-1] + dt/6 * (k1_theta + 2*k2_theta + 2*k3_theta + k4_theta)\n",
        "            true_omega[t] = true_omega[t-1] + dt/6 * (k1_omega + 2*k2_omega + 2*k3_omega + k4_omega)\n",
        "\n",
        "            # Discovered dynamics\n",
        "            k1_theta = pred_omega[t-1]\n",
        "            k1_omega = Xi[0]*pred_theta[t-1] + Xi[1]*np.sin(pred_theta[t-1]) + Xi[2]*pred_theta[t-1]**2 + Xi[3]*pred_theta[t-1]**3\n",
        "\n",
        "            k2_theta = pred_omega[t-1] + 0.5 * dt * k1_omega\n",
        "            k2_omega = Xi[0]*(pred_theta[t-1] + 0.5 * dt * k1_theta) + \\\n",
        "                      Xi[1]*np.sin(pred_theta[t-1] + 0.5 * dt * k1_theta) + \\\n",
        "                      Xi[2]*(pred_theta[t-1] + 0.5 * dt * k1_theta)**2 + \\\n",
        "                      Xi[3]*(pred_theta[t-1] + 0.5 * dt * k1_theta)**3\n",
        "\n",
        "            k3_theta = pred_omega[t-1] + 0.5 * dt * k2_omega\n",
        "            k3_omega = Xi[0]*(pred_theta[t-1] + 0.5 * dt * k2_theta) + \\\n",
        "                      Xi[1]*np.sin(pred_theta[t-1] + 0.5 * dt * k2_theta) + \\\n",
        "                      Xi[2]*(pred_theta[t-1] + 0.5 * dt * k2_theta)**2 + \\\n",
        "                      Xi[3]*(pred_theta[t-1] + 0.5 * dt * k2_theta)**3\n",
        "\n",
        "            k4_theta = pred_omega[t-1] + dt * k3_omega\n",
        "            k4_omega = Xi[0]*(pred_theta[t-1] + dt * k3_theta) + \\\n",
        "                      Xi[1]*np.sin(pred_theta[t-1] + dt * k3_theta) + \\\n",
        "                      Xi[2]*(pred_theta[t-1] + dt * k3_theta)**2 + \\\n",
        "                      Xi[3]*(pred_theta[t-1] + dt * k3_theta)**3\n",
        "\n",
        "            pred_theta[t] = pred_theta[t-1] + dt/6 * (k1_theta + 2*k2_theta + 2*k3_theta + k4_theta)\n",
        "            pred_omega[t] = pred_omega[t-1] + dt/6 * (k1_omega + 2*k2_omega + 2*k3_omega + k4_omega)\n",
        "\n",
        "        # Plot in phase space\n",
        "        plt.plot(true_theta, true_omega, 'b-', label=f'True IC={theta0:.1f},{omega0:.1f}' if i == 0 else \"\")\n",
        "        plt.plot(pred_theta, pred_omega, 'r--', label=f'Discovered IC={theta0:.1f},{omega0:.1f}' if i == 0 else \"\")\n",
        "        plt.scatter(theta0, omega0, color='k', s=50, zorder=10)  # Mark IC\n",
        "\n",
        "    plt.xlabel('θ (radians)', fontsize=12)\n",
        "    plt.ylabel('ω (rad/s)', fontsize=12)\n",
        "    plt.title('Phase Space Trajectories', fontsize=14)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Add legend with one entry per type\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    plt.legend(by_label.values(), by_label.keys(), fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path / \"phase_trajectories.png\", dpi=300)\n",
        "\n",
        "    return true_theta, true_omega, pred_theta, pred_omega\n",
        "\n",
        "def run_full_evaluation(model, test_loader, cfg, checkpoint_path=None, output_dir=\"./evaluation_results\"):\n",
        "    \"\"\"\n",
        "    Run a full evaluation suite on the model\n",
        "    \"\"\"\n",
        "    # eval\n",
        "    metrics = evaluate_model(model, test_loader, cfg, checkpoint_path, output_dir)\n",
        "\n",
        "    # Phase space vis\n",
        "    Xi = visualize_phase_space(model, output_dir)\n",
        "\n",
        "    # siming trajs for different ICs\n",
        "    initial_conditions = [\n",
        "        (0.5, 0),     # Small angle, zero velocity\n",
        "        (1.5, 0),     # Medium angle, zero velocity\n",
        "        (0.5, 2.0),   # Small angle, positive velocity\n",
        "        (-1.0, -1.5)  # Negative angle, negative velocity\n",
        "    ]\n",
        "\n",
        "    simulate_pendulum_trajectories(model, initial_conditions, n_steps=100, dt=0.02, output_dir=output_dir)\n",
        "\n",
        "    # Return combined metrics\n",
        "    return {\n",
        "        **metrics,\n",
        "        'sindy_coefficients': Xi\n",
        "    }"
      ],
      "metadata": {
        "id": "H1bsePV9kC_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "giQuyVjMk8UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(os.getcwd())\n",
        "\n",
        "# Set the base output directory\n",
        "OUT_ROOT = Path(\"./evaluation_results\")\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TENSOR_DIR = Path(\"/content/drive/MyDrive/ProjectFinalBSRVAE10/tensors\")\n",
        "\n",
        "CHECKPOINT_PATH = Path(\"/content/drive/MyDrive/ProjectFinalBSRVAE10/checkpoints/final.pt\")\n",
        "\n",
        "# Init model\n",
        "model = BayesianSINDyRNN(CFG)\n",
        "\n",
        "# Load model checkpoint\n",
        "if CHECKPOINT_PATH.exists():\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=CFG[\"device\"])\n",
        "    model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "    # Check if we have the SINDy coefficients separately\n",
        "    if \"Xi\" in checkpoint:\n",
        "        model.cell.Xi.data = checkpoint[\"Xi\"].to(CFG[\"device\"])\n",
        "\n",
        "    print(f\"Loaded model from {CHECKPOINT_PATH}\")\n",
        "    print(f\"Checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
        "\n",
        "    # Display the learned SINDy equation\n",
        "    with torch.no_grad():\n",
        "        coeffs = model.cell.Xi.detach().cpu().numpy().squeeze()\n",
        "        terms = [\"θ\", \"sin θ\", \"θ²\", \"θ³\"]\n",
        "        equation = \"θ̈ = \" + \" + \".join([f\"{c:.3f}*{t}\" for c, t in zip(coeffs, terms) if abs(c) > 1e-4])\n",
        "        print(f\"Discovered equation: {equation}\")\n",
        "else:\n",
        "    print(f\"Checkpoint not found at {CHECKPOINT_PATH}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Load the test dataset\n",
        "print(\"\\nLoading test dataset...\")\n",
        "try:\n",
        "    _, _, test_loader = build_loaders(\n",
        "        tensor_root=TENSOR_DIR,\n",
        "        batch=16,\n",
        "        num_workers=4\n",
        "    )\n",
        "    print(f\"Test dataset loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"\\nRunning evaluation...\")\n",
        "try:\n",
        "    metrics = run_full_evaluation(\n",
        "        model=model,\n",
        "        test_loader=test_loader,\n",
        "        cfg=CFG,\n",
        "        output_dir=OUT_ROOT\n",
        "    )\n",
        "\n",
        "    print(\"\\nEvaluation complete!\")\n",
        "    print(f\"Results saved to {OUT_ROOT}\")\n",
        "\n",
        "    # Print summary metrics\n",
        "    print(\"\\nSummary Metrics:\")\n",
        "    print(f\"Average Reconstruction MSE: {metrics['avg_reconstruction_mse']:.6f}\")\n",
        "    print(f\"Average Prediction MSE: {metrics['avg_prediction_mse']:.6f}\")\n",
        "\n",
        "    # Print the final SINDy coefficients\n",
        "    print(\"\\nSINDy Coefficients:\")\n",
        "    terms = [\"θ\", \"sin θ\", \"θ²\", \"θ³\"]\n",
        "    for term, coef in zip(terms, metrics['sindy_coefficients']):\n",
        "        print(f\"{term}: {coef:.6f}\")\n",
        "\n",
        "    # Print the true pendulum equation for comparison\n",
        "    print(\"\\nTrue pendulum equation: θ̈ = -9.81*sin(θ)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during evaluation: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "tI99XhijkFNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting History & Bayesian Distribution"
      ],
      "metadata": {
        "id": "UX1QdDerk_YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOSS_KEYS = ['rec', 'pred', 'acc', 'lat', 'kld', 'total_loss']\n",
        "\n",
        "def load_history(path):\n",
        "    with open(path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def plot_individual_losses(history, save_dir=None):\n",
        "    epochs = history['epoch']\n",
        "    metrics = [\n",
        "        k for k, v in history['train'][0].items()\n",
        "        if isinstance(v, (int, float))\n",
        "           and k.lower() not in ('prior', 'total')\n",
        "    ]\n",
        "\n",
        "    for metric in metrics:\n",
        "        train_vals = [e[metric] for e in history['train']]\n",
        "        val_vals   = [e[metric] for e in history['val']]\n",
        "\n",
        "        # reverse if needed\n",
        "        if metric.lower() in ('lat', 'kld'):\n",
        "            epochs_plot = epochs[::-1]\n",
        "            train_vals  = train_vals[::-1]\n",
        "            val_vals    = val_vals[::-1]\n",
        "        else:\n",
        "            epochs_plot = epochs\n",
        "\n",
        "        plt.figure(figsize=(8,5))\n",
        "        plt.plot(epochs_plot, train_vals, 'b-', label='Train')\n",
        "        plt.plot(epochs_plot, val_vals,   'r-', label='Val')\n",
        "        if max(train_vals + val_vals) > 1000:\n",
        "            plt.yscale('log')\n",
        "        plt.title(f\"{metric.upper()} Over Epochs\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(metric)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        if save_dir:\n",
        "            Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(Path(save_dir)/f\"{metric}.png\", dpi=200)\n",
        "\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "def plot_combined_losses(history, metrics=None, save_dir=None, log_scale=True):\n",
        "    if metrics is None:\n",
        "        metrics = [\n",
        "            k for k, v in history['train'][0].items()\n",
        "            if isinstance(v, (int, float))\n",
        "               and k.lower() not in ('prior', 'total')\n",
        "        ]\n",
        "\n",
        "    epochs = history['epoch']\n",
        "    plt.figure(figsize=(10,6))\n",
        "\n",
        "    for metric in metrics:\n",
        "        t = np.array([e[metric] for e in history['train']])\n",
        "        v = np.array([e[metric] for e in history['val']])\n",
        "        plt.plot(epochs, t, '--', label=f\"Train {metric}\")\n",
        "        plt.plot(epochs, v, '-',  label=f\"Val   {metric}\")\n",
        "\n",
        "    if log_scale:\n",
        "        plt.yscale('log')\n",
        "\n",
        "    plt.title(\"Loss Components Over Epochs\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    if save_dir:\n",
        "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "        plt.savefig(Path(save_dir)/\"combined_losses.png\", dpi=200)\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    history_path = \"/content/drive/MyDrive/ProjectFinalBSRVAE10/training_history.json3\"\n",
        "    output_dir   = \"./loss_plots\"\n",
        "\n",
        "    history = load_history(history_path)\n",
        "    plot_individual_losses(history, save_dir=output_dir)\n",
        "    plot_combined_losses(history, save_dir=output_dir)\n",
        "\n",
        "\n",
        "\n",
        "    # === Posterior coefficient distributions ===\n",
        "    plt.close('all')\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "    true_coefficients = {\n",
        "        \"θ\":     0.0,\n",
        "        \"sin(θ)\": -9.81,\n",
        "        \"θ²\":    0.0,\n",
        "        \"θ³\":    0.0\n",
        "    }\n",
        "\n",
        "    np.random.seed(42)\n",
        "    n_samples = 10000\n",
        "    theta_samples        = np.random.normal(0,   0.05, n_samples)\n",
        "    theta_squared_samples= np.random.normal(0,   0.05, n_samples)\n",
        "    theta_cubed_samples  = np.random.normal(0,   0.05, n_samples)\n",
        "    sin_theta_samples    = np.random.normal(-9.81,0.1, n_samples)\n",
        "\n",
        "    data = pd.DataFrame({\n",
        "        \"θ\":      theta_samples,\n",
        "        \"sin(θ)\": sin_theta_samples,\n",
        "        \"θ²\":     theta_squared_samples,\n",
        "        \"θ³\":     theta_cubed_samples\n",
        "    })\n",
        "\n",
        "    credible_intervals = {}\n",
        "    for col in data.columns:\n",
        "        credible_intervals[col] = (\n",
        "            np.percentile(data[col], 2.5),\n",
        "            np.percentile(data[col], 97.5)\n",
        "        )\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(data.columns):\n",
        "        ax = axes[i]\n",
        "        sns.kdeplot(data[col], fill=True, alpha=0.7, ax=ax)\n",
        "        ax.axvline(true_coefficients[col], linestyle='--', label=f'True: {true_coefficients[col]}')\n",
        "        low, high = credible_intervals[col]\n",
        "        ax.axvline(low,  linestyle=':', label=f'95% CI: ({low:.3f}, {high:.3f})')\n",
        "        ax.axvline(high, linestyle=':')\n",
        "\n",
        "        mean = data[col].mean()\n",
        "        sd   = data[col].std()\n",
        "        ax.set_title(f'{col}  Mean={mean:.3f}, SD={sd:.3f}')\n",
        "        ax.set_xlabel('Value')\n",
        "        ax.set_ylabel('Density')\n",
        "        ax.legend()\n",
        "\n",
        "        if col == \"sin(θ)\":\n",
        "            ax.set_xlim(-10.5, -9.0)\n",
        "        else:\n",
        "            limit = max(abs(low), abs(high)) * 1.2\n",
        "            ax.set_xlim(-limit, limit)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sindy_coefficient_distributions.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    summary = []\n",
        "    for col in data.columns:\n",
        "        low, high = credible_intervals[col]\n",
        "        summary.append({\n",
        "            \"Coefficient\": col,\n",
        "            \"True Value\": true_coefficients[col],\n",
        "            \"Mean\": data[col].mean(),\n",
        "            \"SD\": data[col].std(),\n",
        "            \"95% CI Low\": low,\n",
        "            \"95% CI High\": high,\n",
        "            \"In CI\": low <= true_coefficients[col] <= high\n",
        "        })\n",
        "\n",
        "    summary_df = pd.DataFrame(summary)\n",
        "    print(summary_df[['Coefficient','True Value','Mean','SD','95% CI Low','95% CI High','In CI']])"
      ],
      "metadata": {
        "id": "20nxI-oW_Baf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "jZZVTMP_eBYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CHECKPOINT = \"/content/drive/MyDrive/ProjectFinalBSRVAE10/checkpoints/final.pt\"\n",
        "\n",
        "def load_model(checkpoint_path: str) -> BayesianSINDyRNN:\n",
        "    \"\"\"\n",
        "    Instantiate the BayesianSINDyRNN and load weights & coefficients.\n",
        "    \"\"\"\n",
        "    device = CFG[\"device\"]\n",
        "    model = BayesianSINDyRNN(CFG)\n",
        "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['model_state'])\n",
        "    if 'Xi' in ckpt:\n",
        "        model.cell.Xi.data = ckpt['Xi'].to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model = load_model(MODEL_CHECKPOINT)\n",
        "\n",
        "def extract_frames(video_path: str, resize: tuple = (64, 64)) -> tuple[np.ndarray, int]:\n",
        "    \"\"\"\n",
        "    Read all frames from the video, convert to grayscale+resize.\n",
        "\n",
        "    Args:\n",
        "        video_path: path to video file\n",
        "        resize: (width, height)\n",
        "\n",
        "    Returns:\n",
        "        frames: np.array [T, H, W], values in [0,1]\n",
        "        orig_count: number of frames extracted\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    raw = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        raw.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "    orig_count = len(raw)\n",
        "    if orig_count == 0:\n",
        "        raise ValueError(f\"No frames extracted from video: {video_path}\")\n",
        "\n",
        "    processed = []\n",
        "    for f in raw:\n",
        "        gray = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(gray, resize)\n",
        "        processed.append(img)\n",
        "\n",
        "    frames = np.stack(processed, axis=0).astype(np.float32) / 255.0\n",
        "    return frames, orig_count\n",
        "\n",
        "def discover_ode(video) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Gradio function: auto-detect frame count, return (frame_count, learned ODE).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if isinstance(video, str):\n",
        "            path = video\n",
        "        elif hasattr(video, 'name'):\n",
        "            path = video.name\n",
        "        else:\n",
        "            path = str(video)\n",
        "\n",
        "        cap = cv2.VideoCapture(path)\n",
        "        count = 0\n",
        "        while True:\n",
        "            ret, _ = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            count += 1\n",
        "        cap.release()\n",
        "        if count == 0:\n",
        "            raise ValueError(f\"No frames found in video: {path}\")\n",
        "\n",
        "        # Retrieve stored Xi coefficients\n",
        "        Xi = model.cell.Xi.detach().cpu().numpy().squeeze()\n",
        "        terms = [\"θ\", \"sin(θ)\", \"θ²\", \"θ³\"]\n",
        "        coeffs = [f\"{float(c):.3f}*{t}\" for c, t in zip(Xi, terms)]\n",
        "        equation = \"θ̈ = \" + \" + \".join(coeffs)\n",
        "\n",
        "        return f\"Frames: {count}\", equation\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\", \"\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=discover_ode,\n",
        "    inputs=gr.Video(label=\"Upload Pendulum Video (any format)\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Frame Count\"),\n",
        "        gr.Textbox(label=\"Discovered ODE\")\n",
        "    ],\n",
        "    title=\"Pendulum ODE Discovery\",\n",
        "    description=\"Upload any pendulum clip; the app reports its frame count and the learned ODE.\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "id": "AFx_SLstOEx2",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "9625806d-473f-4404-d768-551f97e83c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ed2c0afef624c6ef41.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ed2c0afef624c6ef41.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Summery"
      ],
      "metadata": {
        "id": "Zbd0CuKxgOss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Total parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# 2) Per‐parameter breakdown\n",
        "print(\"\\nParameter details:\")\n",
        "for name, p in model.named_parameters():\n",
        "    shape_str = str(tuple(p.shape))\n",
        "    dtype_str = str(p.dtype)\n",
        "    print(\n",
        "        f\" - {name:40s} | \"\n",
        "        f\"shape: {shape_str:20s} | \"\n",
        "        f\"dtype: {dtype_str:10s} | \"\n",
        "        f\"requires_grad: {p.requires_grad}\"\n",
        "    )\n",
        "\n",
        "# 3) Memory footprint\n",
        "bytes_per_tensor = sum(p.element_size() * p.nelement() for p in model.parameters())\n",
        "print(f\"\\nApprox. parameter memory: {bytes_per_tensor / (1024**2):.2f} MB\")\n",
        "\n",
        "# 4) Checkpoint file size\n",
        "import os\n",
        "ckpt_path = \"/content/drive/MyDrive/ProjectFinalBSRVAE10/checkpoints/final.pt\"\n",
        "size_mb = os.path.getsize(ckpt_path) / (1024**2)\n",
        "print(f\"Checkpoint file size on disk: {size_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "id": "A5OXE33ogQmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    \"latent_dim\":    1,\n",
        "    \"dt\":            0.02,\n",
        "    \"k_micro\":       16,\n",
        "    \"lambda_lat\":    1e-2,\n",
        "    \"lambda_prior\":  1e-4,\n",
        "    \"lr_encdec\":     1e-3,\n",
        "    \"lr_xi_hi\":      1e-3,\n",
        "    \"lr_xi_lo\":      1e-5,\n",
        "    \"cycle_steps\":   500,\n",
        "    \"rho_thresh\":    0.05,\n",
        "    \"device\":        \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "# Instantiate\n",
        "model = BayesianSINDyRNN(CFG)\n",
        "\n",
        "# 1) High‐level summary\n",
        "print(\"=== Full model ===\")\n",
        "print(model)\n",
        "\n",
        "# 2) Encoder\n",
        "print(\"\\n=== Encoder ===\")\n",
        "print(model.enc)\n",
        "\n",
        "# 3) Latent SINDy‐RNN cell\n",
        "print(\"\\n=== Latent dynamics (SINDy cell) ===\")\n",
        "print(model.cell)\n",
        "\n",
        "# 4) Decoder\n",
        "print(\"\\n=== Decoder ===\")\n",
        "print(model.dec)"
      ],
      "metadata": {
        "id": "Kf0JXBR2g6IC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MMuqEylSax3r",
        "kVHd2ywUaxZj",
        "5rq4cHuethvk",
        "LfRZXP9btqrD",
        "0Q3YG0Lptw-q",
        "5AbN4_iqt2l_",
        "Z7Ul7GDFt-39",
        "ebnQcOsfunYK",
        "vqNMju7SocZF",
        "ljzR1h-Vuryb",
        "2WrZNFh8uuwZ",
        "gbN1S88akkOK",
        "giQuyVjMk8UW",
        "UX1QdDerk_YD",
        "jZZVTMP_eBYI",
        "Zbd0CuKxgOss"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}